{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d03dfdf-187a-4557-857a-42e9874edb1b",
   "metadata": {},
   "source": [
    "# Team 68 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57053ba4-1259-40b0-b3b4-225dd056b626",
   "metadata": {},
   "source": [
    "### Adwoa's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4104829-7e43-4e37-8e3a-9297c2a046ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Required for basic python plotting functionality\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Advanced plotting functionality with seaborn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add1c416-4261-41a6-9b5d-71febd9e9348",
   "metadata": {},
   "source": [
    "with open('data/public_up_to_150k_1.csv') as f:\n",
    "    public_150k_1=pd.read_csv(f, delimiter=';')\n",
    "    \n",
    "chunksize = 10 ** 8\n",
    "for chunk in pd.read_csv('data/public_up_to_150k_1.csv', chunksize=chunksize):\n",
    "    process(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2af629-a113-43b1-9b8c-2edd935ed75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Reading public_up_to_150k_1 csv file\n",
    "row_count = 1000\n",
    "for chunk in pd.read_csv('public_up_to_150k_1.csv', chunksize=row_count): \n",
    "    df_1 = chunk # process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c72233-f650-4c4a-ad77-9537379607b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb62bb5b-5e9a-4100-a908-32b90962dfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('public_up_to_150k_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f346e4-e99f-41fa-a41a-8556a7e6d7d0",
   "metadata": {},
   "source": [
    "There are 11 csv files to iterate through, plus the first with an irregular name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e98b17-d540-4a9e-bab0-369b909ba7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Reading public_150k_plus csv file\n",
    "row_count = 1000\n",
    "for chunk in pd.read_csv('data/public_150k_plus.csv', chunksize=row_count): \n",
    "    df_12 = chunk # process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f866c85-7b40-4135-a9d1-e868b517d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_12.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbc7193-172e-410a-8e82-135fb9d7a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding all the dataframes into list\n",
    "frames = [df_1, df_2, df_3, df_4, df_5, df_6, df_7, df_8, df_9, df_10, df_11, df_12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d9078c-1dbf-41fc-acb5-7137573f20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using concat to merge all dataframe into one\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d908645-828d-47df-b5d0-a1fbbd6d3e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac893f07-2ca2-48fa-a482-100de5de5c90",
   "metadata": {},
   "source": [
    "### Or Darnell's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79505e9-2a53-4af4-a90f-2120ce9c7419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0a5cc1-c524-4689-b6e9-3a96c279ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.read_csv('ppploans.csv', nrows=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb82930-3724-4080-8fef-575cce01ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_database = create_engine('sqlite:///csv_database.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6b31df-ccee-4c45-86a1-9cac2e4ae124",
   "metadata": {},
   "outputs": [],
   "source": [
    "csz = 100000\n",
    "i = 0 \n",
    "j = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb2a0a2-e683-483e-9b43-5a85c147c07b",
   "metadata": {},
   "source": [
    "Not sure why it keeps looping here, it returns more index values than it should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d3e43d-dd5f-43cb-85ba-221f7e2060b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in pd.read_csv('ppploans.csv', chunksize = csz, iterator=True): \n",
    "    df = df.rename(columns = {c: c.replace('', '') for c in df.columns})\n",
    "    df.index += j \n",
    "    \n",
    "    df.to_sql('data_use', csv_database, if_exists = 'append')\n",
    "    j = df.index[-1]+1\n",
    "    \n",
    "    print('| index: {}'.format(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee712bd-6db3-463e-abb8-5a74397e1e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query ('SELECT * FROM data_use', csv_database) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
